DUE February 27th

Completed:
1.2.1. Scheduling Infrastructure
	Code Loading
	PCB
	Ready Queue
	Scheduler Logic
	Cleanup
1.2.2. Exec Command
	Single Process
	Multiprocess
1.2.3. Adding Scheduling Policies
	SJF
	RR
1.2.4. SJF with job aging
1.2.5 Background Mode 
	RR30 Policy

Tasks:
	Execution in the background
1.2.6 Multithreaded Scehduler
Testcases
Video (1.2.1 & 1.2.2)

INFO & Notes:
Code Loading: Made an array in shellmemory with 1000 spots and wrote functions
add_line, get_line and load_program to add lines to the program memory, get lines 
from it and insert a whole program from a file. Not sure if we need an program_init
function but choose to leave it for now. I'm also not sure how to test this but
it compiles for now so I think it alright?

PCB: Just defined a struct that holds ints for PID, start index, program_length and 
program counter. I changed the load program function to return where it put it as 
its start instead of where it ends. I'm also not sure which program we're relying
on to know the program length and I think we may need to edit some of the code loading
functions in the future because maybe they should compute the length instead... and as of
right now it won't catch errors where the array runs out of memory (at least not gracefully).

New: 
- added an enqueue and dequeue functions to update the ready_queue. 
- updated source in interpreter.c to load script, create a pcb, add to ready queue, and run the whole queue
- moved pcb and ready_queue structs to .h

source cleanup: need to remove code lines from program_storage after the program is done running

Exec Command: Added exec command. A bit confused about the program behavior when there is only single process (for now I 
just have it call the source command but i don't really understand wether thats the correct behavior- the instructions 
say that it's not a special case so not sure what to do or what to implement). 
I had the different types of processes in a if statement chain so that we can choose behavior for each type of processing. 
I'm not sure if thats the correct implementation but I was very confused about the implementation they describe in instructions. 

Exec w/ Policies: implemented for everything except for the aging policy. The loop where 
it's supposed to go (RR) will have to change a bit. I'm implementing this by always dequeuing from the head of the queue,
and then there are different enqueue functions for different policies. This way we always have a sorted queue (which we need for aging I think).
One assumption I'm making right now is that there's only one exec running at once so no new programs get added after the first enqueue.
Also for SJF, if 2 programs have the same length when they get enqueued, I made the choice to add the most recent one after.

Other new changes:
- moved ready queue and pcb to readyqueue.c file
- load_program function now opens the script and checks if file exists + error if memory is too small
- created a pcb cleanup function to remove the program from storage  **dequeue is what disconnects pcb from ready queue
- added the prog1-2-3 files they give as examples in the src folder to test the policies easily

aging: instructions are kind of confusing, I think an intuitive way to think abt how the queue is updated is 
"initially order your queue in increasing score order, then run + keep head at the front as long as its score is lower or equal to the score
of the next pcb in the queue. When score of next pcb becomes lower, move head to tail of queue"


Implementing "#" in exec:
- updated load_program to have a wrapper function that takes the name of a script and added a function: load_program_file that lets you
create programs from any stream.
- added conditions for checking # in interpreter. 
- the interpreter will check for #. If it finds it, it will create a PCB with the rest of whatever is in the stream (file or input (use ctrl d 
	to insert EOF if you want ot type from the command line)). Then it will add this PCB to the queue so that it is always first to run and then it will
	call exec as normal. There's also a "batch_flag" which gets set to 1 so that when we copy the command arguments we ignore # if it's present. 

I did my own testing with just what I thought of. I was a bit confused by the priority idea but I think it should work?
It has the same behavior as the example execution. 

Multithreaded: 
- when we parse for exec command we check if MT and/or # are present and then set some flags + pass them to the exec command
- exec now deals with setting up stuff for the MT and # options (I moved the # batch pcb stuff to exec)
- exec: first load and enqueue all input programs, then if # enabled we create and enqueue the pcb at the head (so always the first to run), 
	once the ready queue is built, we pick a scheduler based on MT flag and send it all of the info for how to run
- New file: scheduler.c. This had the single threaded and multi threaded options for the scheduler. 
	-- Single threaded hasn't changed. It's the different loops we had in exec before (for the different policies)
	-- Multi creates 2 worker threads which both dequeue from the ready queue simultaneaously. The worker function basically has the RR version 
		of the exec loop, but lock the ready queue when dequeuing/enquing pcbs so that the 2 workers don't mess up the queue
	-- has global mt_flag, quit_requested, and worker_threads so that interpreter.c can access/modify them based on the inputs received
- we also assume that once exec is called with a policy then all the next calls to exec will be with the same policy so don't need to worry 
abt having diff policies at the same time
- modified quit() to join the worker threads, then actually exits when ready queue is empty


Questions:
- making worker function be the one joining the worker threads? was getting a seg fault when its done in quit()?
	but instructions say "If quit is called and the ready queue is not empty, the quit implementation needs to join with the 
	scheduler threads"... is it okay to make quit set a flag and then make the scheduler/worker functions join when the flag is set?
- make sure our understanding/implementation of MT with quit is correct (batch pcb runs first, what if first instruction is quit, etc)
- order of printing bye! when # vs not (eg. should be first when doing exec # then quit immediately, so quit should run first?)
- update: now quit just returns if mt_flag, and exit(0) is done in worker thread after all threads have been joined
			if not using mt flag then just exit(0) so that single threaded scripts work normally
- still getting seg fault when calling quit in the shell directly after doing exec with MT?
	Shell version 1.5 created Dec 2025
	$ exec pA.txt pB.txt pC.txt RR MT
	A
	A
	C
	C
	A
	A
	C
	C
	B
	B
	B
	B
	$ quit
	Bye!
	$ Segmentation fault (core dumped)
- confused where to join threads + exit
- problem with # and MT --> MT3 not printing weird stuff half the time??


All problems were fixed. Seg fault issues were coming from scheduler_ctx not being allocated/freed properly and 
also changed it so that we only free the memory of program storage at the very end before quitting. We don't need 
to be claning the pcbs as they finish running (it messes up with the threads bc they both modify the contents of program storage)